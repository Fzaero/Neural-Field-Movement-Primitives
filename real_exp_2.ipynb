{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c1347c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T14:26:28.241412Z",
     "start_time": "2023-10-03T14:26:27.373710Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from IPython import display\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.display import display as html_width\n",
    "html_width(HTML(\"\"))\n",
    "import random\n",
    "from scipy.spatial import distance\n",
    "import io\n",
    "from matplotlib import patches\n",
    "cm = plt.cm.get_cmap('RdYlBu')\n",
    "import cv2\n",
    "import pickle\n",
    "import point_cloud_utils as pcu\n",
    "\n",
    "Train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d97e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T14:26:28.245950Z",
     "start_time": "2023-10-03T14:26:28.242401Z"
    }
   },
   "outputs": [],
   "source": [
    "manifold_resolution = 20_000\n",
    "\n",
    "# Number of points in the volume to sample around the shape\n",
    "num_vol_pts = 5_000\n",
    "\n",
    "# Number of points on the surface to sample\n",
    "num_surf_pts = 20_000\n",
    "\n",
    "def get_samples_for_mesh(mesh_path):\n",
    "    v, f = pcu.load_mesh_vf(mesh_path)\n",
    "    cv, nv, cf, nf = pcu.connected_components(v, f.astype(np.int32))\n",
    "\n",
    "    # Extract mesh of connected component with most faces\n",
    "    comp_max = np.argmax(nf)\n",
    "    v, f, _, _ = pcu.remove_unreferenced_mesh_vertices(v, f[cf == comp_max])\n",
    "\n",
    "    vm, fm = pcu.make_mesh_watertight(v, f.astype(np.int32), manifold_resolution)\n",
    "    p_vol = (np.random.rand(num_vol_pts, 3))*np.array([0.6,0.6,0.6])-np.array([0.3,0.3,0.01]) \n",
    "    sdf, _, _  = pcu.signed_distance_to_mesh(p_vol, vm, fm)\n",
    "    fid_surf, bc_surf = pcu.sample_mesh_random(vm, fm, num_surf_pts)\n",
    "    f_i, bc = pcu.sample_mesh_random(v, f, num_samples=v.shape[0] * 40)\n",
    "\n",
    "    # Use the face indices and barycentric coordinate to compute sample positions and normals\n",
    "    v_sampled = pcu.interpolate_barycentric_coords(f, f_i, bc, v)\n",
    "    v_sampled =v_sampled[np.abs(v_sampled[:,0])<0.3]\n",
    "    v_sampled =v_sampled[np.abs(v_sampled[:,1])<0.3]\n",
    "    return (vm,fm), (p_vol,sdf), v_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3dc9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T14:26:29.911088Z",
     "start_time": "2023-10-03T14:26:29.289606Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from os.path import join\n",
    "from torch.utils.data import Dataset\n",
    "import trimesh\n",
    "import glob\n",
    "import open3d as o3d\n",
    "import os\n",
    "data_path = \"demo_data/real_world_exp2_exp_ready/\"\n",
    "class SDF_Dataset(Dataset):\n",
    "    def __init__(self,traj_count,num_of_samples=10000):\n",
    "        self.demo_meshes = list()\n",
    "        self.demo_envs = list()\n",
    "        self.traj_count = traj_count\n",
    "        self.sdf_points = list()\n",
    "        self.sdf_values = list()\n",
    "        self.surface_points = list()    \n",
    "        self.demo_t = np.zeros((traj_count,100,1))\n",
    "        self.demo_x = np.zeros((traj_count,100,3))\n",
    "        self.demo_q = np.zeros((traj_count,100,6))\n",
    "        self.num_of_samples=num_of_samples\n",
    "\n",
    "        for p in range(traj_count):\n",
    "            \n",
    "            if not os.path.exists(data_path+str(p)+'_processed/'):\n",
    "                os.makedirs(data_path+str(p)+'_processed/')\n",
    "                with open(data_path+str(p)+\"/data.pickle\", 'rb') as handle:\n",
    "                    data = pickle.load(handle)\n",
    "                mesh, (sdf_points,sdf_values), surface_points = get_samples_for_mesh(data_path+str(p)+\"/mesh_cropped.ply\")\n",
    "                np.save(data_path+str(p)+'_processed/sdf_points',sdf_points)\n",
    "                np.save(data_path+str(p)+'_processed/sdf_values',sdf_values)\n",
    "                np.save(data_path+str(p)+'_processed/surface_points',surface_points)\n",
    "                pcu.save_mesh_vf(data_path+str(p)+'_processed/data.ply', mesh[0], mesh[1])\n",
    "                with open(data_path+str(p)+\"_processed/data.pickle\", 'wb') as handle:\n",
    "                    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            else:\n",
    "                with open(data_path+str(p)+\"_processed/data.pickle\", 'rb') as handle:\n",
    "                    data = pickle.load(handle)   \n",
    "                sdf_points = np.load(data_path+str(p)+'_processed/sdf_points.npy')\n",
    "                sdf_values = np.load(data_path+str(p)+'_processed/sdf_values.npy')*5\n",
    "                sdf_values[sdf_values>1]=1\n",
    "                surface_points = np.load(data_path+str(p)+'_processed/surface_points.npy')\n",
    "                v, f = pcu.load_mesh_vf(data_path+str(p)+'_processed/data.ply')  \n",
    "                mesh=(v,f)\n",
    "            self.demo_t[p,:,0] = np.array(data['t'])-0.5\n",
    "#             self.demo_x[p] = np.array(data['pos_traj'])\n",
    "            self.demo_q[p] = np.array(data['joint_traj'])\n",
    "            self.demo_envs.append(data['env_parameters'])                    \n",
    "            self.demo_meshes.append(mesh)\n",
    "            self.sdf_points.append(sdf_points)\n",
    "            self.sdf_values.append(sdf_values)\n",
    "            self.surface_points.append(surface_points)\n",
    "            \n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.traj_count\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        random_points_on_traj = np.random.choice(np.arange(100),100)\n",
    "        \n",
    "        t_mp = torch.from_numpy(self.demo_t[index,random_points_on_traj]).float()\n",
    "        q_mp = torch.from_numpy(self.demo_q[index,random_points_on_traj]).float()\n",
    "        \n",
    "        \n",
    "        random_points_on_surface = np.random.choice(np.arange(len(self.surface_points[index])),self.num_of_samples//2)\n",
    "        random_points_off_surface = np.random.choice(np.arange(len(self.sdf_values[index])),self.num_of_samples//2)\n",
    "        \n",
    "        x = torch.from_numpy(np.vstack([self.surface_points[index][random_points_on_surface],\n",
    "                       self.sdf_points[index][random_points_off_surface]])).float()\n",
    "\n",
    "        y = {'sdf':torch.from_numpy(np.vstack([np.zeros((self.num_of_samples//2,1)),\n",
    "                             self.sdf_values[index][random_points_off_surface].reshape(-1,1)])).float(),\n",
    "             }\n",
    "        observations =  {\n",
    "            't': t_mp,\n",
    "            'mp': q_mp,\n",
    "            'coords_sdf': x,\n",
    "            'sdf': y['sdf'],\n",
    "            'instance_idx':torch.Tensor([index]).squeeze().long()}\n",
    "    \n",
    "        ground_truth = {'sdf':observations['sdf'],\n",
    "                        'mp':  q_mp}\n",
    "\n",
    "        return observations, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db139f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T14:26:32.279401Z",
     "start_time": "2023-10-03T14:26:32.056970Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from matplotlib import patches\n",
    "%matplotlib inline\n",
    "dataset = SDF_Dataset(9)\n",
    "dataloader = DataLoader(dataset, shuffle=True,batch_size=1, num_workers=0, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5109d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T14:26:32.534775Z",
     "start_time": "2023-10-03T14:26:32.480639Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "observations,_ = dataset[2]\n",
    "surface_points = observations['coords_sdf'][:1000]\n",
    "sdf_points = observations['coords_sdf'][1000:]\n",
    "sdf_values = observations['sdf'][1000:].reshape(-1)\n",
    "ax.scatter3D(sdf_points[sdf_values<0.1,0], sdf_points[sdf_values<0.1,1], sdf_points[sdf_values<0.1,2]);\n",
    "# ax.scatter3D(sdf_points[sdf_values>0,0], sdf_points[sdf_values>0,1], sdf_points[sdf_values>0,2]);\n",
    "ax.scatter3D(surface_points[:,0], surface_points[:,1], surface_points[:,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c461db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from modules import *\n",
    "from meta_modules import HyperNetwork\n",
    "from skimage import measure\n",
    "import plotly.graph_objects as go\n",
    "l1_loss = torch.nn.L1Loss()\n",
    "\n",
    "def task_loss_with_deform(model_output, gt):\n",
    "    embeddings = model_output['latent_vec']    \n",
    "    embeddings_constraint = torch.mean(embeddings ** 2)\n",
    "    deform = model_output['deform']\n",
    "    \n",
    "    sdf_constraint = l1_loss(model_output['sdf'],gt['sdf'])\n",
    "\n",
    "    return {'sdf' :torch.abs(sdf_constraint)* 3e4, \n",
    "            'mp' : ((model_output['mp']-gt['mp'])**2).mean() * 1e5,           \n",
    "            'embeddings_constraint': embeddings_constraint.mean() * 1e6,\n",
    "           }\n",
    "\n",
    "class NFSMP_Shape(nn.Module):\n",
    "    def __init__(self, num_instances,latent_dim=128, model_type='relu', hyper_hidden_layers=2,\n",
    "                 hyper_hidden_features=64,mp_out_size=6,hidden_num=128, affine=True, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.latent_codes = nn.Embedding(num_instances, self.latent_dim)\n",
    "        nn.init.normal_(self.latent_codes.weight, mean=0, std=0)\n",
    "        \n",
    "        self.mp_net = SingleBVPNet(in_features=1,\n",
    "                                   out_features=mp_out_size,L =8,pos_encoding=True)\n",
    "        self.deform_net = SingleBVPNet(in_features=3,\n",
    "                                    out_features=3,L =2,pos_encoding=True)                 \n",
    "        self.sdf_net=SingleBVPNet(in_features=3,out_features=1,L =8,pos_encoding=True)\n",
    "\n",
    "        self.deform_epoch_multiplier = 8.0/2.0\n",
    "        # Hyper-Net  \n",
    "        \n",
    "        self.hyper_net_mp = HyperNetwork(hyper_in_features=self.latent_dim,\n",
    "                                         hyper_hidden_layers=hyper_hidden_layers,\n",
    "                                         hyper_hidden_features=hyper_hidden_features,\n",
    "                                         hypo_module=self.mp_net)           \n",
    "        self.hyper_net_deform= HyperNetwork(hyper_in_features=self.latent_dim,\n",
    "                                         hyper_hidden_layers=hyper_hidden_layers, \n",
    "                                         hyper_hidden_features=hyper_hidden_features,\n",
    "                                         hypo_module=self.deform_net)   \n",
    "        \n",
    "        last_layer = [layer for layer in self.deform_net.modules() if isinstance(layer, BatchLinear)][-1]\n",
    "        torch.nn.init.zeros_(last_layer.weight)\n",
    "        torch.nn.init.zeros_(last_layer.bias)           \n",
    "\n",
    "    def get_hypo_net_weights(self, model_input):\n",
    "        instance_idx = model_input['instance_idx']\n",
    "        embedding = self.latent_codes(instance_idx)\n",
    "        hypo_params_mp = self.hyper_net_mp(embedding)\n",
    "        hypo_params_deform = self.hyper_net_deform(embedding)\n",
    "        return hypo_params_mp, hypo_params_deform, embedding\n",
    "    def get_latent_code(self,instance_idx):\n",
    "\n",
    "        embedding = self.latent_codes(instance_idx)\n",
    "\n",
    "        return embedding\n",
    "    def inference(self,coords_sdf,embedding,epoch = 1000):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_out = dict()\n",
    "            \n",
    "            hypo_params_deform = self.hyper_net_deform(embedding)\n",
    "            model_in = {'coords': coords_sdf}\n",
    "            deform =self.deform_net(model_in,self.deform_epoch_multiplier*epoch, params=hypo_params_deform)['model_out']\n",
    "            \n",
    "            model_in = {'coords': coords_sdf+deform}\n",
    "            model_out['sdf'] =self.sdf_net(model_in,epoch)['model_out']            \n",
    "            return model_out\n",
    "    def inference_mp(self,coords_mp,embedding,epoch = 1000):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_out = dict()\n",
    "            hypo_params_mp = self.hyper_net_mp(embedding)\n",
    "            model_in = {'coords': coords_mp}\n",
    "            model_out['mp'] =self.mp_net(model_in,epoch, params=hypo_params_mp)['model_out']\n",
    "            return model_out     \n",
    "\n",
    "    \n",
    "    def forward(self, model_input,gt,epoch,**kwargs):\n",
    "\n",
    "        instance_idx = model_input['instance_idx']\n",
    "        coords_sdf  = model_input['coords_sdf'] \n",
    "        t = model_input['t']\n",
    "        model_in1 = {'coords': t}\n",
    "        model_in2 = {'coords': coords_sdf}\n",
    "        \n",
    "        hypo_params_mp, hypo_params_deform, embedding = self.get_hypo_net_weights(model_input)\n",
    "        mp = self.mp_net(model_in1,epoch, params=hypo_params_mp)['model_out']      \n",
    "        deform =self.deform_net(model_in2,self.deform_epoch_multiplier*epoch, params=hypo_params_deform)['model_out']\n",
    "        model_in3 = {'coords': coords_sdf+deform}  \n",
    "        \n",
    "        sdf = self.sdf_net(model_in3,epoch)['model_out']\n",
    "\n",
    "        model_out = {'t': t,\n",
    "                     'coords_sdf':coords_sdf,\n",
    "                     'mp':mp,\n",
    "                     'sdf':sdf,\n",
    "                     'deform':deform,                     \n",
    "                     'latent_vec':embedding,}\n",
    "        \n",
    "        losses = task_loss_with_deform(model_out, gt)\n",
    "        return losses\n",
    "\n",
    "def estimate_mesh_from_model(model, epoch, subject_idx, resolution = 64, scale = 0.3 ):\n",
    "    with torch.no_grad():\n",
    "        N=resolution\n",
    "        max_batch=64 ** 3\n",
    "        model.eval()\n",
    "\n",
    "        # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "        voxel_origin = [-1, -1, 0]\n",
    "        voxel_size = 2.0 / (N - 1)\n",
    "\n",
    "        overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "        samples = torch.zeros(N ** 3, 4)\n",
    "\n",
    "        # transform first 3 columns\n",
    "        # to be the x, y, z index\n",
    "        samples[:, 2] = overall_index % N\n",
    "        samples[:, 1] = (overall_index.long() // N) % N\n",
    "        samples[:, 0] = ((overall_index.long() // N) // N) % N\n",
    "\n",
    "        # transform first 3 columns\n",
    "        # to be the x, y, z coordinate\n",
    "        samples[:, 0] = (samples[:, 0] * scale * voxel_size) + scale *voxel_origin[0]\n",
    "        samples[:, 1] = (samples[:, 1] * scale * voxel_size) + scale *voxel_origin[1]\n",
    "        samples[:, 2] = (samples[:, 2] * scale * voxel_size) + scale *voxel_origin[2]\n",
    "        num_samples = N ** 3\n",
    "\n",
    "        samples.requires_grad = False\n",
    "\n",
    "        head = 0\n",
    "        subject_idx = torch.Tensor([subject_idx]).squeeze().long().cuda()[None,...]\n",
    "        embedding = model.get_latent_code(subject_idx)\n",
    "        while head < num_samples:\n",
    "            sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()[None,...]\n",
    "            samples[head : min(head + max_batch, num_samples), 3] = (\n",
    "                model.inference(sample_subset,embedding,epoch)['sdf']\n",
    "                .squeeze()#.squeeze(1)\n",
    "                .detach()\n",
    "                .cpu()\n",
    "            )\n",
    "            head += max_batch\n",
    "\n",
    "        sdf_values = samples[:, 3]\n",
    "        sdf_values = sdf_values.reshape(N, N, N)\n",
    "        v,t,n,_ = measure.marching_cubes(sdf_values.numpy(),0.001,step_size = 1,spacing=[2/N,2/N,2/N])\n",
    "        return scale*(v+np.array(voxel_origin)),t,n\n",
    "def show_mesh(vertices, faces,colors=[]):\n",
    "    x, y, z = zip(*vertices)\n",
    "    xt, yt, zt = zip(*faces)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Mesh3d(\n",
    "                x=x, \n",
    "                y=y, \n",
    "                z=z, \n",
    "                i = list(xt),\n",
    "                j = list(yt),\n",
    "                k = list(zt),\n",
    "                colorscale='jet',\n",
    "                intensity=colors,\n",
    "            ),\n",
    "\n",
    "    ])\n",
    "    fig.show()\n",
    "    return fig    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c56fba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T14:30:23.717696Z",
     "start_time": "2023-10-03T14:30:23.416684Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traj_count=9\n",
    "model = NFSMP_Shape(traj_count,latent_dim = 128,hidden_num=128)\n",
    "model.to(device=torch.device('cuda:0'))\n",
    "optim = torch.optim.Adam([\n",
    "                {'params': model.sdf_net.parameters()},\n",
    "                {'params': model.mp_net.parameters()},\n",
    "                {'params': model.deform_net.parameters()},\n",
    "                {'params': model.hyper_net_deform.parameters()},\n",
    "                {'params': model.hyper_net_mp.parameters()},\n",
    "                {'params': model.latent_codes.parameters(), 'lr': 1e-4},\n",
    "            ],\n",
    "    lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78535593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T14:35:28.971289Z",
     "start_time": "2023-10-03T14:30:27.022451Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "%matplotlib inline\n",
    "\n",
    "if Train: \n",
    "    total_steps=0\n",
    "    epochs=1500\n",
    "    lowest_mp_loss = 1000\n",
    "\n",
    "    with tqdm(total=len(dataloader) * epochs) as pbar:\n",
    "        train_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            if epoch%200==199:\n",
    "                v,t,n = estimate_mesh_from_model(model,epoch,0,128)\n",
    "                show_mesh(v,t)\n",
    "            model.train()\n",
    "            epoch_mp_losses = []        \n",
    "            for step, (model_input, gt) in enumerate(dataloader):\n",
    "\n",
    "                start_time = time.time()\n",
    "                model_input = {key: value.cuda() for key, value in model_input.items()}\n",
    "                gt = {key: value.cuda() for key, value in gt.items()}\n",
    "\n",
    "                losses = model(model_input,gt,epoch)\n",
    "\n",
    "                train_loss = 0.\n",
    "                for loss_name, loss in losses.items():\n",
    "                    single_loss = loss.mean()\n",
    "                    if epoch %100== 0 and step==0:\n",
    "                        print(loss_name,single_loss)\n",
    "                    train_loss += single_loss\n",
    "                epoch_mp_losses.append(losses['mp'].item())\n",
    "                train_losses.append(train_loss.item())\n",
    "                optim.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optim.step()\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(loss=train_loss, time=time.time() - start_time, epoch=epoch)\n",
    "                total_steps += 1\n",
    "            if np.mean(epoch_mp_losses)<lowest_mp_loss:\n",
    "                lowest_mp_loss=np.mean(epoch_mp_losses)\n",
    "                checkpoint = copy.deepcopy(model.state_dict())\n",
    "    model.load_state_dict(checkpoint)\n",
    "    torch.save(model.state_dict(), \"real_exp_2\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc4341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T14:28:19.519392Z",
     "start_time": "2023-10-03T14:28:19.355067Z"
    }
   },
   "outputs": [],
   "source": [
    "if not Train:\n",
    "    model.load_state_dict(torch.load(\"real_exp_2\"))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2500a7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T20:31:15.704812Z",
     "start_time": "2023-02-24T20:31:15.680801Z"
    }
   },
   "outputs": [],
   "source": [
    "def traj_field(model,grid_size = 100,epoch=1000):\n",
    "    tlist = np.linspace(-0.5, 0.5, grid_size)\n",
    "    Z_mp = list() #y.reshape(64,64)\n",
    "    for index in range(9):\n",
    "        with torch.no_grad():\n",
    "            samples = torch.from_numpy(tlist.reshape(-1,1)).float().cuda()            \n",
    "            samples.requires_grad=False\n",
    "\n",
    "            subject_idx = torch.Tensor([index]).squeeze().long().cuda()[None,...]\n",
    "            embedding = model.get_latent_code(subject_idx)\n",
    "            out = model.inference_mp(samples,embedding,epoch=epoch)['mp'].squeeze().detach().cpu().numpy()\n",
    "            Z_mp.append(out.reshape(grid_size,6))\n",
    "            \n",
    "    return Z_mp \n",
    "trajectories = traj_field(model,100,1000)\n",
    "errors = list()\n",
    "for i in range(9):\n",
    "    errors.append(np.linalg.norm(trajectories[i]-dataset.demo_q[i]).mean())\n",
    "print('MSE', np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T14:37:11.293218Z",
     "start_time": "2023-10-03T14:37:09.777916Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "v,t,n = estimate_mesh_from_model(model,1000,1,128)\n",
    "show_mesh(v,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a19eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T19:18:53.432675Z",
     "start_time": "2023-02-24T19:18:53.421736Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.offline  \n",
    "def estimate_mesh_traj_from_model(model, epoch, subject_idx,subject_idx2, resolution = 64,traj_len = 50,scale = 0.3 ):\n",
    "    with torch.no_grad():\n",
    "        N=resolution\n",
    "        max_batch=64 ** 3\n",
    "        model.eval()\n",
    "        subject_idx = torch.Tensor([subject_idx]).squeeze().long().cuda()[None,...]\n",
    "        subject_idx2 = torch.Tensor([subject_idx2]).squeeze().long().cuda()[None,...]\n",
    "        embedding1 = model.get_latent_code(subject_idx)\n",
    "        embedding2 = model.get_latent_code(subject_idx2)\n",
    "        \n",
    "        \n",
    "        # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "        voxel_origin = [-1, -1, 0]\n",
    "        voxel_size = 2.0 / (N - 1)\n",
    "\n",
    "        overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "        mesh_list=list()\n",
    "        for interp in range(traj_len):\n",
    "            embedding = embedding1+(embedding2-embedding1)/(traj_len-1.0)*(interp)\n",
    "            samples = torch.zeros(N ** 3, 4)\n",
    "\n",
    "            # transform first 3 columns\n",
    "            # to be the x, y, z index\n",
    "            samples[:, 2] = overall_index % N\n",
    "            samples[:, 1] = (overall_index.long() // N) % N\n",
    "            samples[:, 0] = ((overall_index.long() // N) // N) % N\n",
    "\n",
    "            # transform first 3 columns\n",
    "            # to be the x, y, z coordinate\n",
    "            samples[:, 0] = (samples[:, 0] * scale * voxel_size) + scale *voxel_origin[0]\n",
    "            samples[:, 1] = (samples[:, 1] * scale * voxel_size) + scale *voxel_origin[1]\n",
    "            samples[:, 2] = (samples[:, 2] * scale * voxel_size) + scale *voxel_origin[2]\n",
    "            num_samples = N ** 3\n",
    "\n",
    "            samples.requires_grad = False\n",
    "\n",
    "            head = 0\n",
    "\n",
    "\n",
    "            while head < num_samples:\n",
    "                sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()[None,...]\n",
    "                samples[head : min(head + max_batch, num_samples), 3] = (\n",
    "                    model.inference(sample_subset,embedding,epoch)['sdf']\n",
    "                    .squeeze()#.squeeze(1)\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                )\n",
    "                head += max_batch\n",
    "\n",
    "            sdf_values = samples[:, 3]\n",
    "            sdf_values = sdf_values.reshape(N, N, N)\n",
    "            \n",
    "            v,t,n,_ = measure.marching_cubes(sdf_values.numpy(),0.0035,step_size = 1,spacing=[2/N,2/N,2/N])\n",
    "            mesh_list.append((scale*(v+np.array(voxel_origin)),t,n))\n",
    "        return mesh_list\n",
    "\n",
    "def draw_mesh_list(mesh_list,fname):\n",
    "       \n",
    "    fig = go.Figure(data = [\n",
    "            go.Mesh3d(\n",
    "                            x=[],y=[],z=[], \n",
    "                            i = [],j = [],k =[],\n",
    "                            colorscale='jet',\n",
    "                        ),\n",
    "\n",
    "        ],\n",
    "        layout=go.Layout(\n",
    "                title=\"Interpolation Animation\",\n",
    "                paper_bgcolor='rgba(0,0,0,0)',\n",
    "                plot_bgcolor='rgba(0,0,0,0)'\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(scene = dict(\n",
    "                        xaxis=dict(range=[-1, 1], autorange=False,\n",
    "                                showgrid= True, zeroline= False,visible= False,  ),\n",
    "                        yaxis=dict(range=[-1, 1], autorange=False,\n",
    "                                showgrid= True, zeroline= False,visible= False,  ),\n",
    "                        zaxis=dict(range=[-1, 1], autorange=False,\n",
    "                                showgrid= True, zeroline= False,visible= False,  ),\n",
    "                        )\n",
    "                     )\n",
    "\n",
    "    # Frames\n",
    "    frames=list()\n",
    "    opacity = 1\n",
    "    for i in range(0,len(mesh_list)):\n",
    "        v,t,_ = mesh_list[i]\n",
    "        x, y, z = zip(*v)\n",
    "        xt, yt, zt = zip(*t)\n",
    "        go_mesh_list = list()\n",
    "        go_mesh_list.append(go.Mesh3d(x=x,y=y,z=z, \n",
    "                        i = list(xt),j = list(yt),k =list(zt),\n",
    "                        color='gray',\n",
    "                        opacity = opacity,\n",
    "                        name = 'Predicted Surface Mesh'\n",
    "                        ),)\n",
    "        frames.append(\n",
    "            go.Frame(data= go_mesh_list,\n",
    "                    name=f'frame{i}',\n",
    "                )\n",
    "            )\n",
    "    fig.update(frames=frames)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def frame_args(duration):\n",
    "        return {\n",
    "                \"frame\": {\"duration\": duration},\n",
    "                \"mode\": \"immediate\",\n",
    "                \"fromcurrent\": True,\n",
    "                \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n",
    "                }\n",
    "\n",
    "\n",
    "    sliders = [\n",
    "        {\"pad\": {\"b\": 10, \"t\": 60},\n",
    "         \"len\": 0.9,\n",
    "         \"x\": 0.1,\n",
    "         \"y\": 0,\n",
    "\n",
    "         \"steps\": [\n",
    "                     {\"args\": [[f.name], frame_args(0)],\n",
    "                      \"label\": str(k),\n",
    "                      \"method\": \"animate\",\n",
    "                      } for k, f in enumerate(fig.frames)\n",
    "                  ]\n",
    "         }\n",
    "            ]\n",
    "\n",
    "    fig.update_layout(\n",
    "\n",
    "        updatemenus = [{\"buttons\":[\n",
    "                        {\n",
    "                            \"args\": [None, frame_args(50)],\n",
    "                            \"label\": \"Play\", \n",
    "                            \"method\": \"animate\",\n",
    "                        },\n",
    "                        {\n",
    "                            \"args\": [[None], frame_args(0)],\n",
    "                            \"label\": \"Pause\", \n",
    "                            \"method\": \"animate\",\n",
    "                      }],\n",
    "\n",
    "                    \"direction\": \"left\",\n",
    "                    \"pad\": {\"r\": 10, \"t\": 20},\n",
    "                    \"type\": \"buttons\",\n",
    "                    \"x\": 0.1,\n",
    "                    \"y\": 0,\n",
    "                }\n",
    "             ],\n",
    "             sliders=sliders\n",
    "        )\n",
    "\n",
    "    fig.update_layout(sliders=sliders)\n",
    "\n",
    "    camera = dict(\n",
    "        up=dict(x=0, y=-0.707, z=0.707),\n",
    "        center=dict(x=0, y=0, z=0),\n",
    "        eye=dict(x=0, y=1, z=-1.25)\n",
    "    )\n",
    "    fig.update_layout(scene_aspectmode='cube')\n",
    "    fig.update_layout(scene_camera=camera)\n",
    "    plotly.offline.plot(fig, filename=fname+'.html', auto_open=False)\n",
    "    del fig    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e0272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T19:18:59.145801Z",
     "start_time": "2023-02-24T19:18:53.433411Z"
    }
   },
   "outputs": [],
   "source": [
    "traj = [\n",
    "    [0,1],\n",
    "    [1,2],\n",
    "    [2,3],\n",
    "    [3,4],\n",
    "    [4,5],\n",
    "    [5,6],\n",
    "    [6,7],\n",
    "    [7,8],\n",
    "]\n",
    "mesh_traj = []\n",
    "for pair in traj:\n",
    "    mesh_traj = mesh_traj + estimate_mesh_traj_from_model(model,2000,pair[0],pair[1],64,10)\n",
    "draw_mesh_list(mesh_traj,'Interpolation_Test')  \n",
    "# Open Interpolation_Test.html file to view it. Pause it once, and start again for smoother viewing.\n",
    "# When file is initially opened, html file will look at the object from bottom, you can rotate it with left mouse button"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NF Torch 2",
   "language": "python",
   "name": "mf_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
